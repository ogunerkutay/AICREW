{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1ETrZQqo0rl41Z3h6be-Gv7KmWAg_8FTj",
      "authorship_tag": "ABX9TyNKD8aAz6TLo3tDpG+xWfZb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ogunerkutay/AICREW/blob/main/AICrew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 0: Required Installs\n"
      ],
      "metadata": {
        "id": "w2rTRx9zLMzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "!pip install gitpython\n",
        "!pip install langchain\n",
        "!pip install langchain-community\n",
        "!pip install langchain_google_genai\n",
        "!pip install faiss-gpu\n",
        "!pip install wikipedia\n",
        "!pip install crewai"
      ],
      "metadata": {
        "id": "vxHjU-W8z2Qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Environment Setup and Basic Imports\n"
      ],
      "metadata": {
        "id": "wIUqkYLEISGE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nmXeod8XrxJR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31ad5934-16dc-492d-df8a-3994b1ab7afc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current working directory: /content\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import git\n",
        "\n",
        "def get_api_key(key_name):\n",
        "    \"\"\"Get API key from Colab secrets or environment variables based on the environment.\"\"\"\n",
        "    try:\n",
        "        # First, try to fetch from Colab secrets if available\n",
        "        from google.colab import userdata\n",
        "        return userdata.get(key_name)\n",
        "    except ImportError:\n",
        "        # If not in Colab, load from .env file\n",
        "        from dotenv import load_dotenv\n",
        "        load_dotenv()\n",
        "        return os.environ.get(key_name)\n",
        "\n",
        "# API Keys\n",
        "gemini_api_key = get_api_key(\"GEMINI_API_KEY\")\n",
        "google_api_key = get_api_key(\"GOOGLE_API_KEY\")\n",
        "\n",
        "\n",
        "# Get and print the current working directory\n",
        "current_directory = os.getcwd()\n",
        "print(\"Current working directory:\", current_directory)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Configuration and Initializations"
      ],
      "metadata": {
        "id": "YmnBntaXIiOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2: Configuration and Initializations\n",
        "from langchain.globals import set_debug\n",
        "from langchain.embeddings import CacheBackedEmbeddings\n",
        "from langchain.globals import set_debug\n",
        "from langchain.storage import LocalFileStore\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "# Set debug mode\n",
        "set_debug(False)\n",
        "\n",
        "# To load gemini (this api is for free: https://makersuite.google.com/app/apikey)\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", verbose=True, temperature=0.1, google_api_key=gemini_api_key, convert_system_message_to_human=True)\n",
        "\n",
        "# Create a local file store for caching embeddings\n",
        "store = LocalFileStore(\"./cache/\")\n",
        "\n",
        "core_embeddings_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=google_api_key)\n",
        "\n",
        "# Setup embedder with cache\n",
        "embedder = CacheBackedEmbeddings.from_bytes_store(\n",
        "    core_embeddings_model,\n",
        "    store,\n",
        "    namespace = core_embeddings_model.model\n",
        ")\n"
      ],
      "metadata": {
        "id": "OYPUp3h0Ij28"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Document Processing Functions"
      ],
      "metadata": {
        "id": "0i4weLw9Iyuf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "def load_and_process_document(file_path, chunk_size=1000, chunk_overlap=0):\n",
        "    \"\"\"Load a document, split it into chunks, and process it for vector store.\"\"\"\n",
        "    # Load a document\n",
        "    loader = TextLoader(file_path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    # Split the document into chunks\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    return text_splitter.split_documents(documents)\n",
        "\n",
        "# Check if running in Google Colab\n",
        "running_in_colab = 'google.colab' in str(get_ipython())\n",
        "\n",
        "if running_in_colab:\n",
        "    # If running in Colab, mount Google Drive and set the directory there\n",
        "    #from google.colab import drive\n",
        "    #drive.mount('/content/drive')\n",
        "\n",
        "    # Define the Google Drive directory for documents\n",
        "    document_directory = '/content/drive/My Drive/rag/game.txt'\n",
        "else:\n",
        "    # If running locally, use the local file system\n",
        "    document_directory = \"/mnt/c/Users/ogune/OneDrive/Desktop/MYAI/merai/rag/game.txt\"\n",
        "\n",
        "# Load documents from the directory\n",
        "document_texts = load_and_process_document(document_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAMFLYF0IzkX",
        "outputId": "11ef5ce7-36b3-4c63-f661-9c5777b3b0aa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain.text_splitter:Created a chunk of size 1667, which is longer than the specified 1000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4: RetrievalQA Chain"
      ],
      "metadata": {
        "id": "f9LOHoxAJrzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.callbacks import StdOutCallbackHandler\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "def create_vector_store(documents_texts, embedder):\n",
        "    \"\"\"Create and populate a FAISS vector store.\"\"\"\n",
        "    if documents_texts:\n",
        "        from langchain_community.vectorstores import FAISS\n",
        "        return FAISS.from_documents(documents_texts, embedder)\n",
        "    else:\n",
        "        print(\"No documents provided for vector store creation.\")\n",
        "        return None\n",
        "\n",
        "# Create and populate the vector store\n",
        "vectorstore = create_vector_store(document_texts, embedder)\n",
        "\n",
        "# Instantiate a retriever\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "handler = StdOutCallbackHandler()\n",
        "qa_with_sources_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    retriever=retriever,\n",
        "    callbacks=[handler],\n",
        "    return_source_documents=True\n",
        ")"
      ],
      "metadata": {
        "id": "gRwRpuPHJx6S"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 5: Tools Initialization"
      ],
      "metadata": {
        "id": "C6BeWuxt1gY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.tools import tool\n",
        "from langchain.agents.load_tools import load_tools\n",
        "from langchain_community.agent_toolkits import FileManagementToolkit\n",
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper, SearxSearchWrapper\n",
        "\n",
        "# Define a custom tool for the agent using the RAG mechanism\n",
        "@tool\n",
        "def rag_tool(query: str) -> str:\n",
        "    \"\"\"\n",
        "    A tool to perform Retrieval Augmented Generation.\n",
        "\n",
        "    Args:\n",
        "        query (str): The query string for which to generate a response.\n",
        "\n",
        "    Returns:\n",
        "        str: The generated response.\n",
        "    \"\"\"\n",
        "    response = qa_with_sources_chain({\"query\": query})\n",
        "    return response['result']\n",
        "\n",
        "# Initialize File Management Toolkit\n",
        "working_directory = TemporaryDirectory()\n",
        "print(\"Temporary directory path:\", working_directory.name)\n",
        "file_tool = FileManagementToolkit(\n",
        "    root_dir=str(working_directory.name),\n",
        "    selected_tools=[\"read_file\", \"write_file\", \"list_directory\"]\n",
        "    )\n",
        "\n",
        "file_tools = file_tool.get_tools()\n",
        "\n",
        "# Define the SearxNG search tool\n",
        "@tool\n",
        "def searxng_search_tool(query: str) -> str:\n",
        "    \"\"\"\n",
        "    A tool to perform a search using SearxNG.\n",
        "\n",
        "    Args:\n",
        "        query (str): The search query string.\n",
        "\n",
        "    Returns:\n",
        "        str: The search results.\n",
        "    \"\"\"\n",
        "    # Replace 'your_searxng_host' with the host of your SearxNG instance\n",
        "    searx_host = 'http://127.0.0.1:8888'\n",
        "    search = SearxSearchWrapper(searx_host=searx_host)\n",
        "\n",
        "    results = search.run(query)\n",
        "    return results\n",
        "\n",
        "# Initialize Wikipedia Tool\n",
        "wikipedia_api_wrapper = WikipediaAPIWrapper()\n",
        "wikipedia_tool = WikipediaQueryRun(api_wrapper=wikipedia_api_wrapper)\n",
        "\n",
        "# Initialize Requests Tools\n",
        "request_tools = load_tools([\"requests_all\"])\n",
        "\n",
        "# Loading Human Tools\n",
        "human_tool = load_tools([\"human\"])\n",
        "\n",
        "# Define the Project Supervisor tool\n",
        "@tool\n",
        "def project_supervisor_tool(commit_message: str, content: str) -> str:\n",
        "    \"\"\"\n",
        "    A tool to simulate the review and approval of code changes by a project supervisor.\n",
        "    - commit_message: The message associated with the commit.\n",
        "    - content: The content of the code changes.\n",
        "    Returns approval status as a string.\n",
        "    \"\"\"\n",
        "    # Simulate review process\n",
        "    print(f\"Reviewing changes: {commit_message}\\nCode Changes:\\n{content}\")\n",
        "    approval = input(\"Do you approve these changes? (yes/no): \").strip().lower()\n",
        "    if approval == 'yes':\n",
        "        return \"Changes approved\"\n",
        "    else:\n",
        "        return \"Changes not approved\"\n",
        "\n",
        "\n",
        "# Define Code Execution Tool\n",
        "@tool\n",
        "def execute_code(code: str, file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Executes the given Python code and returns its output.\n",
        "\n",
        "    Args:\n",
        "        code (str): Python code to execute.\n",
        "        file_path (str): Path to the file where the code will be written before execution.\n",
        "\n",
        "    Returns:\n",
        "        str: The standard output or error from executing the code.\n",
        "    \"\"\"\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(code)\n",
        "    try:\n",
        "        output = subprocess.run(['python', file_path], capture_output=True, text=True, check=True)\n",
        "        return output.stdout\n",
        "    except subprocess.CalledProcessError as e:\n",
        "        return e.stderr\n",
        "\n",
        "# Define Static Analysis Tool\n",
        "@tool\n",
        "def static_analysis(code: str) -> str:\n",
        "    \"\"\"\n",
        "    Performs static analysis on the provided code to check for syntax errors.\n",
        "\n",
        "    Args:\n",
        "        code (str): Python code to analyze.\n",
        "\n",
        "    Returns:\n",
        "        str: Results of the static analysis.\n",
        "    \"\"\"\n",
        "    # Use a static analysis library or implement your own logic\n",
        "    # Placeholder for static analysis result\n",
        "    return \"No syntax errors found\"\n",
        "\n",
        "# Define Security Vulnerability Scanner Tool\n",
        "@tool\n",
        "def security_scan(code: str) -> str:\n",
        "    \"\"\"\n",
        "    Scans the provided code for known security vulnerabilities.\n",
        "\n",
        "    Args:\n",
        "        code (str): Python code to scan.\n",
        "\n",
        "    Returns:\n",
        "        str: Results of the security scan.\n",
        "    \"\"\"\n",
        "    # Use a security scanning library or API\n",
        "    # Placeholder for security scan result\n",
        "    return \"No security vulnerabilities found\"\n",
        "\n",
        "# Define Output Assessment Tool\n",
        "@tool\n",
        "def assess_output(code: str, expected_output: str) -> str:\n",
        "    \"\"\"\n",
        "    Compares the actual output of the code with the expected output.\n",
        "\n",
        "    Args:\n",
        "        code (str): Python code to execute.\n",
        "        expected_output (str): Expected output of the code.\n",
        "\n",
        "    Returns:\n",
        "        str: Assessment result indicating if the output matches the expected output.\n",
        "    \"\"\"\n",
        "    # Logic to compare actual and expected output\n",
        "    # Placeholder for output assessment result\n",
        "    return \"Output matches expected result\"\n",
        "\n",
        "# Define Bandit Security Analysis Tool\n",
        "@tool\n",
        "def bandit_analysis(file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Runs Bandit security analysis on the Python file at the given path.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the Python file to analyze.\n",
        "\n",
        "    Returns:\n",
        "        str: Results of the Bandit analysis.\n",
        "    \"\"\"\n",
        "    result = subprocess.run(['bandit', '-r', file_path, '-f', 'text'], capture_output=True, text=True)\n",
        "    return result.stdout\n",
        "\n",
        "# Define Safety Vulnerability Scanner Tool\n",
        "@tool\n",
        "def safety_scan(file_path: str) -> str:\n",
        "    \"\"\"\n",
        "    Runs a Safety vulnerability scan on the Python file at the given path.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the Python file to scan.\n",
        "\n",
        "    Returns:\n",
        "        str: Results of the Safety scan.\n",
        "    \"\"\"\n",
        "    result = subprocess.run(['safety', 'check', '--file', file_path, '--full-report'], capture_output=True, text=True)\n",
        "    return result.stdout\n",
        "\n",
        "combined_tools =  [wikipedia_tool, rag_tool, project_supervisor_tool, execute_code, static_analysis, security_scan, assess_output, bandit_analysis, safety_scan] + file_tools + request_tools + human_tool\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAc-IMQ11jB-",
        "outputId": "9c4c23cd-27b0-4c3d-a65d-282349eb7f18"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temporary directory path: /tmp/tmpnf9052tk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 6: Agents and Crew Initialization"
      ],
      "metadata": {
        "id": "p_qVSHWZLF0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from crewai import Agent, Task, Crew, Process\n",
        "\n",
        "# Define the different roles for the software development team\n",
        "# Create a software development team\n",
        "product_owner = Agent(\n",
        "    role=\"Product Owner\",\n",
        "    goal=\"Define the product vision, prioritize features, and guide the development process.\",\n",
        "    backstory=\"You are responsible for defining the direction of the mobile game and ensuring it meets user expectations.\",\n",
        "    llm=llm,\n",
        "    tools=[*combined_tools]\n",
        ")\n",
        "\n",
        "devops_engineer = Agent(\n",
        "    role=\"DevOps Engineer\",\n",
        "    goal=\"Set up deployment pipelines and manage the infrastructure for the application.\",\n",
        "    backstory=\"As a DevOps expert, you will ensure smooth deployment and operation of the applications\",\n",
        "    llm=llm,\n",
        "    tools=[*combined_tools]\n",
        ")\n",
        "\n",
        "database_expert = Agent(\n",
        "    role=\"Database Expert\",\n",
        "    goal=\"Design and optimize the database structure for the application.\",\n",
        "    backstory=\"As a database expert, you will create a robust database schema and optimize queries for efficient data retrieval.\",\n",
        "    llm=llm,\n",
        "    tools=[*combined_tools]\n",
        ")\n",
        "\n",
        "backend_developer = Agent(\n",
        "    role=\"Backend Developer\",\n",
        "    goal=\"Build the backend logic and APIs of the application using C# and .NET Core.\",\n",
        "    backstory=\"Leverage your expertise in C# and .NET Core to develop a scalable and efficient backend system.\",\n",
        "    llm=llm,\n",
        "    tools=[*combined_tools]\n",
        ")\n",
        "\n",
        "middleware_expert = Agent(\n",
        "    role=\"Middleware Developer\",\n",
        "    goal=\"Develop middleware components for communication between the frontend and backend systems.\",\n",
        "    backstory=\"Your role is crucial in ensuring smooth data flow between the frontend and backend components.\",\n",
        "    llm=llm,\n",
        "    tools=[*combined_tools]\n",
        ")\n",
        "\n",
        "frontend_developer = Agent(\n",
        "    role=\"Frontend Developer\",\n",
        "    goal=\"Create the user interface and user experience of the mobile game using Unity.\",\n",
        "    backstory=\"Utilize Unity to design and implement an engaging and user-friendly frontend for the application.\",\n",
        "    llm=llm,\n",
        "    tools=[*combined_tools]\n",
        ")\n",
        "\n",
        "tester = Agent(\n",
        "    role=\"QA Tester\",\n",
        "    goal=\"Conduct thorough testing to identify and report bugs in the application.\",\n",
        "    backstory=\"Your testing skills are crucial in ensuring the quality and reliability of the application.\",\n",
        "    llm=llm,\n",
        "    tools=[*combined_tools]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Define tasks for the team\n",
        "tasks = [\n",
        "    Task(description=\"Design the database schema for the mobile game.\", agent=database_expert),\n",
        "    Task(description=\"Develop middleware components for data communication.\", agent=middleware_expert),\n",
        "    Task(description=\"Implement backend logic and APIs using C# and .NET Core.\", agent=backend_developer),\n",
        "    Task(description=\"Create the user interface and user experience using Unity.\", agent=frontend_developer),\n",
        "    Task(description=\"Perform thorough testing and report any bugs found.\", agent=tester),\n",
        "    Task(description=\"Set up deployment pipelines and manage infrastructure.\", agent=devops_engineer),\n",
        "    Task(description=\"Define the product vision and prioritize features.\", agent=product_owner)\n",
        "]\n",
        "\n",
        "crew = Crew(\n",
        "    agents=[product_owner, devops_engineer, database_expert, backend_developer, middleware_expert, frontend_developer, tester],\n",
        "    tasks=tasks,\n",
        "    verbose=2,\n",
        "    process=Process.sequential\n",
        ")\n"
      ],
      "metadata": {
        "id": "gm5JHe04LGe7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 7: Execution and Results Handling"
      ],
      "metadata": {
        "id": "lSIk9VHHLgSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from tempfile import TemporaryDirectory\n",
        "from langchain.storage import LocalFileStore\n",
        "\n",
        "# Kick off the crew to start the development process\n",
        "result = crew.kickoff()\n",
        "print(\"######################\")\n",
        "print(result)\n",
        "\n",
        "# Temporary directory setup for working\n",
        "# Temporary directory setup\n",
        "working_directory = TemporaryDirectory()\n",
        "print(\"Temporary directory path:\", working_directory.name)\n",
        "\n",
        "# Check if running in Google Colab\n",
        "running_in_colab = 'google.colab' in str(get_ipython())\n",
        "\n",
        "if running_in_colab:\n",
        "    # If running in Colab, mount Google Drive and set the directory there\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Define the Google Drive directory\n",
        "    google_drive_dir = '/content/drive/My Drive/results'\n",
        "    Path(google_drive_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Copy files to the Google Drive directory\n",
        "    shutil.copytree(working_directory.name, google_drive_dir)\n",
        "    print(f\"Copied files to {google_drive_dir}\")\n",
        "else:\n",
        "    # If running locally, use the local file system\n",
        "    local_dir = Path(\"/mnt/C:/Users/ogune/OneDrive/Desktop/results\")\n",
        "\n",
        "    # Copy files to the local directory\n",
        "    shutil.copytree(working_directory.name, local_dir)\n",
        "    print(f\"Copied files to {local_dir}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "obbKEBJDLiGy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "96102183-1a40-428a-f685-2add817025c9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEBUG]: Working Agent: Database Expert\n",
            "[INFO]: Starting Task: Design the database schema for the mobile game.\n"
          ]
        }
      ]
    }
  ]
}
